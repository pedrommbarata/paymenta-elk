input {
	http {
		port => 8080
		type => "api"
	}

	http {
		port => 8081
		type => "identity"
	}
}
# Parse the incoming HTTP, to ensure it is enconded as JSON
filter {
    if !("split_events" in [tags]) {
		json {
            source => "message"
			remove_field => ["message"]
        }
	}
}
filter{
	#Serilog HTTP sink can send multiple events
	#Split events, so Elasticsearch receives one event at a time
	split { 
		field => "events"
		target=> "paymenta_event"
		add_tag => ["events_split"]
		remove_field => ["events"]
	}

	json{
		source => "[paymenta_event][Properties][details]"
		target => "[paymenta_event][Properties][details]"
	}
}

filter{
	mutate{
		add_field => ["PaymentaLogLevel", "%{[paymenta_event][Level]}"]
		add_field => ["RequestID","%{[paymenta_event][Properties][RequestId]}"]
		add_field => ["lc_index_identifier", "%{[paymenta_event][Level]}"]
		#remove_field => ["latinum_event"]		
	}
	mutate {
		lowercase => [ "lc_index_identifier" ]
	}

	mutate {
    	add_field => { "token" => "rKeoHvdGMHIpkrtorOOPzjpXhWkHHYud" }
	}
}

##Drop filter
#filter {
#	if !("Warning" in [LatinumLogLevel]) { 
#		drop{ } 
#	}
#}

output {
	stdout { codec => rubydebug }
    elasticsearch {
		index => "logstash-%{type}-%{lc_index_identifier}-%{+YYYY.MM.dd}"	
		hosts => [ "localhost:9200" ]
		hosts => [ "http://listener.logz.io:8070/?token=rKeoHvdGMHIpkrtorOOPzjpXhWkHHYud" ]
    }
}